{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprroach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Install Prerequisites\n",
    "# import sys\n",
    "# import nltk\n",
    "# !{sys.executable} -m pip install bs4 lxml wordcloud scikit-learn scikit-plot\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Data Preprocessing\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import resample\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Display\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_set.csv')\n",
    "test_data = pd.read_csv('test_set.csv')\n",
    "df_train = train_data.copy() #For EDA on raw data\n",
    "df_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    \"\"\"\n",
    "    Apply data cleaning steps to raw data.\n",
    "    \"\"\"\n",
    "    df['token'] = df['text'].apply(TweetTokenizer().tokenize) ## first we tokenize\n",
    "    df['punc'] = df['token'].apply(lambda x : [i for i in x if i not in string.punctuation])## remove punctuations\n",
    "    df['dig'] = df['punc'].apply(lambda x: [i for i in x if i not in list(string.digits)]) ## remove digits\n",
    "    df['final'] = df['dig'].apply(lambda x: [i for i in x if len(i) > 1]) ## remove all words with only 1 character\n",
    "    return df['final']\n",
    "train_data['final'] = clean(train_data)\n",
    "test_data['final'] = clean(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_speech(word):\n",
    "    \"\"\"\n",
    "    Find part of speech of word if part of speech is either noun, verb, adjective etc and add it to a list.\n",
    "    \"\"\"\n",
    "    probable_part_of_speech = wordnet.synsets(word) ## finding word that is most similar (synonyms) for semantic reasoning\n",
    "    pos_counts = Counter() ## instantiating our counter class\n",
    "    pos_counts[\"n\"] = len([i for i in probable_part_of_speech if i.pos()==\"n\"])\n",
    "    pos_counts[\"v\"] = len([i for i in probable_part_of_speech if i.pos()==\"v\"])\n",
    "    pos_counts[\"a\"] = len([i for i in probable_part_of_speech if i.pos()==\"a\"])\n",
    "    pos_counts[\"r\"] = len([i for i in probable_part_of_speech if i.pos()==\"r\"])\n",
    "    most_likely_part_of_speech = pos_counts.most_common(1)[0][0] ## will extract the most likely part of speech from the list\n",
    "    return most_likely_part_of_speech\n",
    "\n",
    "normalizer = WordNetLemmatizer()\n",
    "\n",
    "train_data['final'] = train_data['final'].apply(lambda x: [normalizer.lemmatize(token, get_part_of_speech(token)) for token in x])\n",
    "test_data['final'] = test_data['final'].apply(lambda x: [normalizer.lemmatize(token, get_part_of_speech(token)) for token in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>punc</th>\n",
       "      <th>dig</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[umgaqo-siseko, wenza, amalungiselelo, kumazik...</td>\n",
       "      <td>[umgaqo-siseko, wenza, amalungiselelo, kumazik...</td>\n",
       "      <td>[umgaqo-siseko, wenza, amalungiselelo, kumazik...</td>\n",
       "      <td>[umgaqo-siseko, wenza, amalungiselelo, kumazik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>[i-dha, iya, kuba, nobulumko, bokubeka, umsebe...</td>\n",
       "      <td>[i-dha, iya, kuba, nobulumko, bokubeka, umsebe...</td>\n",
       "      <td>[i-dha, iya, kuba, nobulumko, bokubeka, umsebe...</td>\n",
       "      <td>[i-dha, iya, kuba, nobulumko, bokubeka, umsebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>[the, province, of, kwazulu-natal, department,...</td>\n",
       "      <td>[the, province, of, kwazulu-natal, department,...</td>\n",
       "      <td>[the, province, of, kwazulu-natal, department,...</td>\n",
       "      <td>[the, province, of, kwazulu-natal, department,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[o, netefatša, gore, o, ba, file, dilo, ka, mo...</td>\n",
       "      <td>[o, netefatša, gore, o, ba, file, dilo, ka, mo...</td>\n",
       "      <td>[o, netefatša, gore, o, ba, file, dilo, ka, mo...</td>\n",
       "      <td>[netefatša, gore, ba, file, dilo, ka, moka, tš...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [umgaqo-siseko, wenza, amalungiselelo, kumazik...   \n",
       "1  [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...   \n",
       "2  [the, province, of, kwazulu-natal, department,...   \n",
       "3  [o, netefatša, gore, o, ba, file, dilo, ka, mo...   \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...   \n",
       "\n",
       "                                                punc  \\\n",
       "0  [umgaqo-siseko, wenza, amalungiselelo, kumazik...   \n",
       "1  [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...   \n",
       "2  [the, province, of, kwazulu-natal, department,...   \n",
       "3  [o, netefatša, gore, o, ba, file, dilo, ka, mo...   \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...   \n",
       "\n",
       "                                                 dig  \\\n",
       "0  [umgaqo-siseko, wenza, amalungiselelo, kumazik...   \n",
       "1  [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...   \n",
       "2  [the, province, of, kwazulu-natal, department,...   \n",
       "3  [o, netefatša, gore, o, ba, file, dilo, ka, mo...   \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...   \n",
       "\n",
       "                                               final  \n",
       "0  [umgaqo-siseko, wenza, amalungiselelo, kumazik...  \n",
       "1  [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...  \n",
       "2  [the, province, of, kwazulu-natal, department,...  \n",
       "3  [netefatša, gore, ba, file, dilo, ka, moka, tš...  \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(X_train.apply(' '.join))\n",
    "X_val = list(X_val.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# vect_save_path = \"TfidfVectorizer.pkl\"\n",
    "# with open(vect_save_path,'wb') as file:\n",
    "#     pickle.dump(vectorizer,file)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9945454545454545\n",
      "Model Runtime: 5.91 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afr</th>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.994671</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbl</th>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.975535</td>\n",
       "      <td>0.984568</td>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>0.995320</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot</th>\n",
       "      <td>0.996753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998374</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssw</th>\n",
       "      <td>0.993031</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.994764</td>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsn</th>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ven</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xho</th>\n",
       "      <td>0.993651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zul</th>\n",
       "      <td>0.976510</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.981450</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.994545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.994537</td>\n",
       "      <td>0.994749</td>\n",
       "      <td>0.994629</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.994567</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.994541</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "afr            0.992908  0.996441  0.994671   281.000000\n",
       "eng            1.000000  1.000000  1.000000   297.000000\n",
       "nbl            0.993769  0.975535  0.984568   327.000000\n",
       "nso            1.000000  0.990683  0.995320   322.000000\n",
       "sot            0.996753  1.000000  0.998374   307.000000\n",
       "ssw            0.993031  0.996503  0.994764   286.000000\n",
       "tsn            0.993289  0.996633  0.994958   297.000000\n",
       "tso            1.000000  1.000000  1.000000   253.000000\n",
       "ven            1.000000  1.000000  1.000000   322.000000\n",
       "xho            0.993651  1.000000  0.996815   313.000000\n",
       "zul            0.976510  0.986441  0.981450   295.000000\n",
       "accuracy       0.994545  0.994545  0.994545     0.994545\n",
       "macro avg      0.994537  0.994749  0.994629  3300.000000\n",
       "weighted avg   0.994567  0.994545  0.994541  3300.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelstart = time.time()\n",
    "logreg = LogisticRegression(C=1000, multi_class='ovr', solver='saga', random_state=42, max_iter=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "logreg_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "results = pd.DataFrame(report).transpose()\n",
    "# results.to_csv(\"logreg_report.csv\")\n",
    "results\n",
    "# model_save_path = \"logreg_model.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(logreg,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "\n",
    "X = list(X.apply(' '.join))\n",
    "X_test = list(X_test.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(C=1000, multi_class='ovr', solver='saga', random_state=42, max_iter=10)\n",
    "logreg.fit(X, y)\n",
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission File\n",
    "results = pd.DataFrame({\"index\":test_data['index'],\"lang_id\": y_test})\n",
    "results.to_csv(\"D:\\Temp\\initial_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9951515151515151\n",
      "Model Runtime: 25.31 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afr</th>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbl</th>\n",
       "      <td>0.996904</td>\n",
       "      <td>0.984709</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>0.995320</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssw</th>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsn</th>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ven</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xho</th>\n",
       "      <td>0.984277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992076</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zul</th>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.989831</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.995152</td>\n",
       "      <td>0.995152</td>\n",
       "      <td>0.995152</td>\n",
       "      <td>0.995152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.995188</td>\n",
       "      <td>0.995250</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.995183</td>\n",
       "      <td>0.995152</td>\n",
       "      <td>0.995154</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "afr            0.996429  0.992883  0.994652   281.000000\n",
       "eng            1.000000  1.000000  1.000000   297.000000\n",
       "nbl            0.996904  0.984709  0.990769   327.000000\n",
       "nso            1.000000  0.990683  0.995320   322.000000\n",
       "sot            1.000000  1.000000  1.000000   307.000000\n",
       "ssw            0.993007  0.993007  0.993007   286.000000\n",
       "tsn            0.993289  0.996633  0.994958   297.000000\n",
       "tso            1.000000  1.000000  1.000000   253.000000\n",
       "ven            1.000000  1.000000  1.000000   322.000000\n",
       "xho            0.984277  1.000000  0.992076   313.000000\n",
       "zul            0.983165  0.989831  0.986486   295.000000\n",
       "accuracy       0.995152  0.995152  0.995152     0.995152\n",
       "macro avg      0.995188  0.995250  0.995206  3300.000000\n",
       "weighted avg   0.995183  0.995152  0.995154  3300.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelstart = time.time()\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "logreg_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "results = pd.DataFrame(report).transpose()\n",
    "# results.to_csv(\"logreg_report.csv\")\n",
    "results\n",
    "# model_save_path = \"logreg_model.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(logreg,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "\n",
    "X = list(X.apply(' '.join))\n",
    "X_test = list(X_test.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission File\n",
    "results = pd.DataFrame({\"index\":test_data['index'],\"lang_id\": y_test})\n",
    "results.to_csv(\"D:\\Temp\\initial_submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9954545454545455\n",
      "Model Runtime: 320.77 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afr</th>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbl</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978593</td>\n",
       "      <td>0.989181</td>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>0.995320</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot</th>\n",
       "      <td>0.996753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998374</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssw</th>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsn</th>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.994958</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ven</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xho</th>\n",
       "      <td>0.990506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zul</th>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.986577</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.995475</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.995527</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.995507</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "afr            0.996429  0.992883  0.994652   281.000000\n",
       "eng            1.000000  1.000000  1.000000   297.000000\n",
       "nbl            1.000000  0.978593  0.989181   327.000000\n",
       "nso            1.000000  0.990683  0.995320   322.000000\n",
       "sot            0.996753  1.000000  0.998374   307.000000\n",
       "ssw            0.996503  0.996503  0.996503   286.000000\n",
       "tsn            0.993289  0.996633  0.994958   297.000000\n",
       "tso            1.000000  1.000000  1.000000   253.000000\n",
       "ven            1.000000  1.000000  1.000000   322.000000\n",
       "xho            0.990506  1.000000  0.995231   313.000000\n",
       "zul            0.976744  0.996610  0.986577   295.000000\n",
       "accuracy       0.995455  0.995455  0.995455     0.995455\n",
       "macro avg      0.995475  0.995628  0.995527  3300.000000\n",
       "weighted avg   0.995507  0.995455  0.995456  3300.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelstart = time.time()\n",
    "svc = SVC(gamma = 0.8, C = 10, random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_val)\n",
    "svc_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "results = pd.DataFrame(report).transpose()\n",
    "# results.to_csv(\"svc_report.csv\")\n",
    "results\n",
    "# model_save_path = \"svc_model.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(svc,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "\n",
    "X = list(X.apply(' '.join))\n",
    "X_test = list(X_test.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "svc = SVC(gamma = 0.8, C = 10, random_state=42)\n",
    "svc.fit(X, y)\n",
    "y_test = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission File\n",
    "results = pd.DataFrame({\"index\":test_data['index'],\"lang_id\": y_test})\n",
    "results.to_csv(\"D:\\Temp\\initial_submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelstart = time.time()\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_val)\n",
    "svc_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "results = pd.DataFrame(report).transpose()\n",
    "# results.to_csv(\"svc_report.csv\")\n",
    "results\n",
    "# model_save_path = \"svc_model.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(svc,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "\n",
    "X = list(X.apply(' '.join))\n",
    "X_test = list(X_test.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X, y)\n",
    "y_test = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission File\n",
    "results = pd.DataFrame({\"index\":test_data['index'],\"lang_id\": y_test})\n",
    "results.to_csv(\"D:\\Temp\\initial_submission5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9960606060606061\n",
      "Model Runtime: 1.83 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afr</th>\n",
       "      <td>0.996454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbl</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978593</td>\n",
       "      <td>0.989181</td>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot</th>\n",
       "      <td>0.996753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998374</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssw</th>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsn</th>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ven</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xho</th>\n",
       "      <td>0.990506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zul</th>\n",
       "      <td>0.979933</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.986532</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.996061</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>0.996061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.996142</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.996096</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>0.996059</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "afr            0.996454  1.000000  0.998224   281.000000\n",
       "eng            1.000000  1.000000  1.000000   297.000000\n",
       "nbl            1.000000  0.978593  0.989181   327.000000\n",
       "nso            1.000000  0.993789  0.996885   322.000000\n",
       "sot            0.996753  1.000000  0.998374   307.000000\n",
       "ssw            0.996503  0.996503  0.996503   286.000000\n",
       "tsn            0.996633  0.996633  0.996633   297.000000\n",
       "tso            1.000000  1.000000  1.000000   253.000000\n",
       "ven            1.000000  1.000000  1.000000   322.000000\n",
       "xho            0.990506  1.000000  0.995231   313.000000\n",
       "zul            0.979933  0.993220  0.986532   295.000000\n",
       "accuracy       0.996061  0.996061  0.996061     0.996061\n",
       "macro avg      0.996071  0.996249  0.996142  3300.000000\n",
       "weighted avg   0.996096  0.996061  0.996059  3300.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelstart = time.time() \n",
    "linsvc = LinearSVC()\n",
    "linsvc.fit(X_train, y_train)\n",
    "y_pred = linsvc.predict(X_val)\n",
    "linsvc_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "results = pd.DataFrame(report).transpose()\n",
    "# results.to_csv(\"linsvc_report.csv\")\n",
    "results\n",
    "# model_save_path = \"linsvc_model.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(linsvc,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "\n",
    "X = list(X.apply(' '.join))\n",
    "X_test = list(X_test.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "linsvc = LinearSVC()\n",
    "linsvc.fit(X, y)\n",
    "y_test = linsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission File\n",
    "results = pd.DataFrame({\"index\":test_data['index'],\"lang_id\": y_test})\n",
    "results.to_csv(\"D:\\Temp\\initial_submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9978787878787879\n",
      "Model Runtime: 0.14 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afr</th>\n",
       "      <td>0.996454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbl</th>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.987768</td>\n",
       "      <td>0.992320</td>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssw</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsn</th>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tso</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ven</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xho</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zul</th>\n",
       "      <td>0.986577</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.991568</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.997879</td>\n",
       "      <td>0.997879</td>\n",
       "      <td>0.997879</td>\n",
       "      <td>0.997879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.997871</td>\n",
       "      <td>0.997991</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.997889</td>\n",
       "      <td>0.997879</td>\n",
       "      <td>0.997879</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "afr            0.996454  1.000000  0.998224   281.000000\n",
       "eng            1.000000  1.000000  1.000000   297.000000\n",
       "nbl            0.996914  0.987768  0.992320   327.000000\n",
       "nso            1.000000  0.996894  0.998445   322.000000\n",
       "sot            1.000000  1.000000  1.000000   307.000000\n",
       "ssw            1.000000  1.000000  1.000000   286.000000\n",
       "tsn            0.996633  0.996633  0.996633   297.000000\n",
       "tso            1.000000  1.000000  1.000000   253.000000\n",
       "ven            1.000000  1.000000  1.000000   322.000000\n",
       "xho            1.000000  1.000000  1.000000   313.000000\n",
       "zul            0.986577  0.996610  0.991568   295.000000\n",
       "accuracy       0.997879  0.997879  0.997879     0.997879\n",
       "macro avg      0.997871  0.997991  0.997926  3300.000000\n",
       "weighted avg   0.997889  0.997879  0.997879  3300.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelstart= time.time()\n",
    "multinb = MultinomialNB()\n",
    "multinb.fit(X_train, y_train)\n",
    "y_pred = multinb.predict(X_val)\n",
    "multinb_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "results = pd.DataFrame(report).transpose()\n",
    "# results.to_csv(\"multinb_report.csv\")\n",
    "results\n",
    "# model_save_path = \"multinb_model.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(multinb,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data\n",
    "X = train_data['final']\n",
    "y = train_data['lang_id']\n",
    "X_test = test_data['final']\n",
    "\n",
    "X = list(X.apply(' '.join))\n",
    "X_test = list(X_test.apply(' '.join))\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "multinb = MultinomialNB()\n",
    "multinb.fit(X, y)\n",
    "y_test = multinb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission File\n",
    "results = pd.DataFrame({\"index\":test_data['index'],\"lang_id\": y_test})\n",
    "results.to_csv(\"D:\\Temp\\initial_submission6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing\n",
    "X = df['text'].astype(str)\n",
    "y = df['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Models\n",
    "LogReg = LogisticRegression()\n",
    "LinSVC = LinearSVC()\n",
    "NB = MultinomialNB()\n",
    "onevrest = OneVsRestClassifier(LinearSVC(),n_jobs=4)\n",
    "vectorizer = TfidfVectorizer(\n",
    "                             min_df=2, \n",
    "                             max_df=0.9,strip_accents='unicode',\n",
    "                             analyzer='word',\n",
    "                             ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "tfidf = vectorizer.fit(X_train)\n",
    "X_train = tfidf.transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Models\n",
    "linsvcmodel = LinSVC.fit(X_train,y_train) #fits this pipeline using the training data\n",
    "naivebayesmodel = NB.fit(X_train,y_train)\n",
    "logisticregression = LogReg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Model\n",
    "text_clf = linsvcmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       155\n",
      "         eng       1.00      1.00      1.00       139\n",
      "         nbl       1.00      0.99      1.00       142\n",
      "         nso       0.99      1.00      1.00       160\n",
      "         sot       1.00      0.99      1.00       148\n",
      "         ssw       1.00      1.00      1.00       168\n",
      "         tsn       1.00      1.00      1.00       140\n",
      "         tso       1.00      1.00      1.00       146\n",
      "         ven       1.00      1.00      1.00       147\n",
      "         xho       1.00      1.00      1.00       156\n",
      "         zul       0.99      1.00      1.00       149\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "Accuracy score : 0.9987878787878788\n",
      "f1 score : 0.9987877382869665\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score\n",
    "from sklearn import metrics\n",
    "print(classification_report(y_test,predictions))\n",
    "print(f\"Accuracy score : {accuracy_score(y_test,predictions)}\")\n",
    "print(f\"f1 score : {f1_score(y_test,predictions,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predictions = text_clf.predict(vectorizer.transform(test_df[\"text\"].astype(str)))\n",
    "\n",
    "kaggle_df = pd.DataFrame(\n",
    "    {'index': test_df['index'],\n",
    "     'lang_id': kaggle_predictions\n",
    "    })\n",
    "\n",
    "kaggle_df.to_csv(\"D:\\Temp\\hack_submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Model\n",
    "text_clf = naivebayesmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       155\n",
      "         eng       1.00      1.00      1.00       139\n",
      "         nbl       1.00      0.99      0.99       142\n",
      "         nso       1.00      1.00      1.00       160\n",
      "         sot       1.00      1.00      1.00       148\n",
      "         ssw       1.00      1.00      1.00       168\n",
      "         tsn       1.00      1.00      1.00       140\n",
      "         tso       1.00      1.00      1.00       146\n",
      "         ven       1.00      1.00      1.00       147\n",
      "         xho       1.00      1.00      1.00       156\n",
      "         zul       0.99      1.00      0.99       149\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "Accuracy score : 0.9987878787878788\n",
      "f1 score : 0.9987876208897485\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score\n",
    "from sklearn import metrics\n",
    "print(classification_report(y_test,predictions))\n",
    "print(f\"Accuracy score : {accuracy_score(y_test,predictions)}\")\n",
    "print(f\"f1 score : {f1_score(y_test,predictions,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predictions = text_clf.predict(vectorizer.transform(test_df[\"text\"].astype(str)))\n",
    "\n",
    "kaggle_df = pd.DataFrame(\n",
    "    {'index': test_df['index'],\n",
    "     'lang_id': kaggle_predictions\n",
    "    })\n",
    "\n",
    "kaggle_df.to_csv(\"D:\\Temp\\hack_submission3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Model\n",
    "text_clf = logisticregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       155\n",
      "         eng       1.00      1.00      1.00       139\n",
      "         nbl       0.99      0.99      0.99       142\n",
      "         nso       1.00      1.00      1.00       160\n",
      "         sot       1.00      0.99      1.00       148\n",
      "         ssw       1.00      1.00      1.00       168\n",
      "         tsn       1.00      0.99      1.00       140\n",
      "         tso       1.00      1.00      1.00       146\n",
      "         ven       1.00      1.00      1.00       147\n",
      "         xho       0.99      1.00      0.99       156\n",
      "         zul       0.99      0.99      0.99       149\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "Accuracy score : 0.996969696969697\n",
      "f1 score : 0.9969715727573613\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score\n",
    "from sklearn import metrics\n",
    "print(classification_report(y_test,predictions))\n",
    "print(f\"Accuracy score : {accuracy_score(y_test,predictions)}\")\n",
    "print(f\"f1 score : {f1_score(y_test,predictions,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predictions = text_clf.predict(vectorizer.transform(test_df[\"text\"].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df = pd.DataFrame(\n",
    "    {'index': test_df['index'],\n",
    "     'lang_id': kaggle_predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv(\"D:\\Temp\\hack_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
